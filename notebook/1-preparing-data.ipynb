{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing Data\n",
    "\n",
    "In this project, we will use Yelp online reviews as a dataset, and mainly focus on building a filter by analyzing online text reviews. For more information of dataset, [find this].\n",
    "\n",
    "In this first notebook, we start process dataset by normalize and pretrain the dataset. Further notebooks will use different learning algorithms to train our refined dataset.\n",
    "\n",
    "Let's import some packages and data files.\n",
    "\n",
    "[find this]:(http://odds.cs.stonybrook.edu/yelpnyc-dataset/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torchtext\n",
    "from torchtext import data\n",
    "import spacy\n",
    "import nltk\n",
    "\n",
    "content = np.loadtxt(\"../data/reviewContent\", dtype=np.str, delimiter=\"\\t\")\n",
    "data = np.loadtxt(\"../data/metadata\", \n",
    "\t\tdtype={'names': ('user_id', 'prod_id', 'rating', 'label', 'date'), \n",
    "        'formats': (np.int_, np.int_, np.float, np.int_, '|S11')}, delimiter=\"\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Regroup & Split\n",
    "From raw data files, for each sample they contains:\n",
    "* metadata\n",
    "```\n",
    "<user_id> <restaurant_id> <rating> <label> <date>\n",
    "```\n",
    "* reviewContent\n",
    "```\n",
    "<user_id> <restaurant_id> <date> <review>\n",
    "```\n",
    "\n",
    "\n",
    "For this project we have to rearrange those sample as one sample dataset:\n",
    "\n",
    "| Label | Rating | Review |\n",
    "| :-----------: |:-------------:| :-----|\n",
    "| 1 for real, -1 for fake    | 5.0 | The food at ... seated. |\n",
    "\n",
    "Here is what we get:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = content[:, 3].reshape(content.shape[0], 1)\n",
    "dt = np.array([data['user_id'], data['prod_id'], data['label'], data['rating']])\n",
    "rst = np.hstack([dt.T, sc])\n",
    "np.random.shuffle(rst)\n",
    "\n",
    "train_size = round(rst.shape[0] * 0.6)\n",
    "cv_size = round(rst.shape[0] * 0.2)\n",
    "tst_size = rst.shape[0] - train_size - cv_size\n",
    "\n",
    "np.savetxt('../data/input/train', rst[:train_size], fmt='%s', delimiter='\\t')\n",
    "np.savetxt('../data/input/dev', rst[train_size:(train_size+cv_size)], fmt='%s', delimiter='\\t')\n",
    "np.savetxt('../data/input/test', rst[(train_size+cv_size):], fmt='%s', delimiter='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Normalization\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'label': '-1.0', 'text': ['thi', 'littl', 'place', 'in', 'soho', 'is', 'wonder', '.', 'i', 'had', 'a', 'lamb', 'sandwich', 'and', 'a', 'glass', 'of', 'wine', '.', 'the', 'price', 'shock', 'me', 'for', 'how', 'small', 'the', 'serv', 'wa', ',', 'but', 'then', 'again', ',', 'thi', 'is', 'soho', '.', 'the', 'staff', 'can', 'be', 'a', 'littl', 'snotti', 'and', 'rude', ',', 'but', 'the', 'food', 'is', 'great', ',', 'just', 'do', \"n't\", 'expect', 'world-class', 'servic', '.']}\n"
     ]
    }
   ],
   "source": [
    "ps = nltk.stem.porter.PorterStemmer()\n",
    "\n",
    "def tokenizer (sentence):\n",
    "    tk = nltk.word_tokenize(sentence)\n",
    "    for i in range(len(tk)):\n",
    "        tk[i] = ps.stem(tk[i]) # Stemming\n",
    "    return tk\n",
    "\n",
    "TEXT = torchtext.data.Field(sequential=True, tokenize=tokenizer, lower=True)\n",
    "LABEL = torchtext.data.LabelField(sequential=False, dtype=torch.float)\n",
    "fields = [(None, None), (None, None), ('label', LABEL), (None, None), ('text', TEXT)]\n",
    "\n",
    "\n",
    "# Generate dataset for torchtext\n",
    "train_data, val_data, test_data = torchtext.data.TabularDataset.splits(path='../data/input', train='train',\n",
    "        validation='dev', test='test', format = 'tsv', fields=fields)\n",
    "print(vars(train_data.examples[0]))\n",
    "\n",
    "# Build vocab\n",
    "TEXT.build_vocab(train_data, vectors=\"glove.6B.100d\") #\n",
    "LABEL.build_vocab(train_data)\n",
    "\n",
    "# Create batch and iterate dataset\n",
    "BATCH_SIZE = [64, 64, 64]\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "train_iter, val_iter, test_iter = torchtext.data.Iterator.splits(\n",
    "        (train_data, val_data, test_data),\n",
    "        batch_sizes=BATCH_SIZE, device=device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
